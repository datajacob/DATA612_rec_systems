{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3719c94e-bd61-4503-b21a-57cd1fba08e6",
   "metadata": {},
   "source": [
    "## Research Discussion Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaab22f-e02c-4fcb-ae3d-12b33811895a",
   "metadata": {},
   "source": [
    "#### App Store Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52823b10-cce9-412e-aade-375d5aea7843",
   "metadata": {},
   "source": [
    "One prominent type of recommender system I've interacted with over the years is app download recommendations, specifically in the Apple App Store. Funny enough, if I go to the app store right now, I have to scroll down quite a bit to find a sections labeled thingss like \"Apps You Might Like\" and \"For You,\" as most of the top categories are more universal (\"Must-Have Apps\") and/or thematic (\"Harness Your Productivity\"). When I look at \"Apps You Might Like,\" the list seems to be content-based, as it includes a sports news app and a Spanish-learning app--two realms I've been occupied with lately. Certainly my phone sees the genre-tags for apps I've been interacting with a lot lately (ESPN: Sports, ConjuGato: Language-Learning) and recommends similarly themed apps. It's also possible they are using collaborative filtering, knowing that people who spend time on ESPN also do so with the Athletic.\n",
    "\n",
    "Generally I think the algorithm is good at surfacing apps I might be interested with. The problem is that with apps, unlike with movies, my goal is to have a limited number of apps to accomplish what I need them to. I actually don't want 20 language-learning apps, I want 3! And the fact that I spend so much time on those 3 may not mean I want more of them, but rather that I am satisfied with their service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74eae4-377d-4389-88b4-77f41e9a38de",
   "metadata": {},
   "source": [
    "#### Attacks on Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e6844-2978-47da-ad75-555314311724",
   "metadata": {},
   "source": [
    "One interesting example of both recommendation abuse potential and mitigation is Community Notes, a system first adopted on a large social media platform by Twitter (later X) that Meta is now in the process of launching on its own platforms. Community Notes are user-written snippets meant to provide additional context to posts, often when those posts are misleading, and only appear to most users once enough contributors to the program have rated the note as helpful. Multiple notes can be written for the same post, but it will only show the note that moves furthest up the rankings.\n",
    "\n",
    "Theoretically this means that a bunch of like-minded contributors could coordinate to either make a note visible or invisible. However, the system has built in safeguards to prevent this, such as using a \"bridging algorithm\" that requires some degree of predicted ideological diversity among voters, based on notes they've rated before. There are also additional \"break glass\" measures so the platform can tweak the system's operations when it seems to be subject to abuse. It's far from perfect, but it is possible to improve recommendation algorithms to achieve program goals more consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4853d5c-eaf9-4473-b879-53354050f268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
