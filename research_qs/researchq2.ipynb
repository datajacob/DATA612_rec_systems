{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d500be-705d-425c-ab36-6e9fcb730aab",
   "metadata": {},
   "source": [
    "#### Research Question 2: Spotify Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9602e-0f98-4a84-af9c-ca015a6305c3",
   "metadata": {},
   "source": [
    "One thing that stood out to me from the video for this week's research question was the flexible nature of interpreting \"ratings\" from users, and the sometimes implicit nature of inferring user preferences. Sure, sometimes users provide likes or star ratings on products, and these can become valuable training data for predictors. But there is not single objective way to build these training sets, and Spotify can learn an incredible amount from the choices users make even if they don't provide additional, explicit feedback beyond listening to song (or continuing to listen to it, or listening to it multiple times).\n",
    "\n",
    "Another thing I found interesting was how Spotify changed the way their system was built as their data grew. I've enjoyed playing around with dummy data for learning purposes, but most of what I've used so far has been **much** smaller than Spotify's data, and it's not feasible to run local Jupyter notebooks for many millions of people's daily listening data. In Spotify's case, they started out using Hadoop but switched to Spark because it let them keep data in memory, which made everything run faster and more smoothly. This was especially important for training their recommendation model, which needs to do a lot of back-and-forth calculations. By reducing the amount of time spent reading and writing data, they could handle the huge scale of their user base and music catalog without slowing things down. It was a good reminder that smart engineering choices can make a big difference in how well a machine learning system works in the real world.\n",
    "\n",
    "I also liked hearing about how they fine-tuned the way their system shares and updates information across computers. Instead of treating all the data equally, they grouped certain pieces together to avoid unnecessary communication between servers. That kind of behind-the-scenes work isn’t always obvious when thinking about recommendation systems, but it’s key to making them work at a large scale. Altogether, the talk helped me see that building a good recommender system isn't just about the algorithm — it's also about understanding user behavior, handling tons of data efficiently, and paying attention to how everything is connected under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9701950-fa75-46b2-91d8-6ba550712a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
