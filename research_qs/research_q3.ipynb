{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcd2366-73ae-4d6f-8e15-1d17776aeabb",
   "metadata": {},
   "source": [
    "### Research Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f840e0-baf4-4ea0-a961-f7ea579534fa",
   "metadata": {},
   "source": [
    "In recent years, \"the TikTok algorithm\" has earned a great deal of attention and news coverage for its apparent ability to hook users in an endless scroll with relatively little user input--just the normal engagement metrics (likes, comments, shares) and, crucially, the time spent watching a particular clip before swiping. Instagram created Reels in response, relying on similar technology and finding a great deal of success themselves.\n",
    "\n",
    "However, discussion of these algorithms has inevitably led to people question whether each person's individualized algorithm has the potential to get them \"stuck\" in a particular \"region\" of the app, and the potential ramifications of this. Addiction is certainly a problem; an effective algorithm is one that can keep people scrolling all day, which is of special concern when an app's audience skews quite young, as TikTok's does. But even putting usage time aside, algorithmic pigeon-holing has potentially massive consequences on both a personal and societal scale.\n",
    "\n",
    "One popular way of testing TikTok's recommender systems--in the absence of algorithmic transparency from the company itself--is to start \"fresh\" accounts, conduct some specified behavior, and take note of what content the account is served. Some researchers using this method have found that in the US, \"Republican-seeded accounts received 11.8% more party-aligned recommendations compared to their Democratic-seeded counterparts, and Democratic-seeded accounts were exposed to 7.5% more opposite-party recommendations on average.\" This finding demonstrates that a.) users can be quickly funneled into thematically consistent content with the potential to reinforce certain views, and b.) that the effect may differ for certain political parties. (Source: https://arxiv.org/html/2501.17831v1)\n",
    "\n",
    "The algorithm doesn't only carry stakes for the audience, but for creators as well. If I like a video, TikTok doesn't necessarily know why, but it seems to pick up on viewership trends and promote content in ways that are difficult for creators to comprehend. Economically-minded creators who have a viral moment are therefore incentivized to recreate it in some way, or use trending music, fostering homogenization on the platform. (Source: https://www.ijssh.org/vol11/1055-EB4032.pdf)\n",
    "\n",
    "Ultimately, people are free to seek and make the content they'd like on these platforms, within the confines of those platforms' policies. But because the algorithms are so effective at surfacing content users enjoy, they have perhaps become the dominant means of consumption for a number of platforms. In TikTok's case, they have said so directly (Source: https://www.tiktok.com/discover/tiktok-traffic-sources-explained). So yes, ultimately I think recommender systems can and do reinforce unethical targeting and segmentation, even if they also offer great discovery and community-building opportunities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
